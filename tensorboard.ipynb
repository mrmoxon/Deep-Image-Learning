{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1312197558.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    rm -rf ./logs/\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST (pre-existing train and test sets)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Concatenate the training and test sets (we want to split the training data into training, validation and test sets with a 70:20:10 ratio)\n",
    "x = np.concatenate((x_train, x_test))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3)\n",
    "# Split the validation data into validation and test sets\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_val, y_val, test_size=1/3)\n",
    "\n",
    "# Define the model architecture\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28), name='layers_flatten'),  # Flatten the input\n",
    "    tf.keras.layers.Dense(512, activation='relu', name='layers_dense'),    # First hidden layer\n",
    "    tf.keras.layers.Dropout(0.2, name='layers_dropout'),                   # Dropout layer\n",
    "    tf.keras.layers.Dense(10, activation='softmax', name='layers_dense_2') # Output layer\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.2582 - accuracy: 0.9237 - val_loss: 0.1403 - val_accuracy: 0.9597\n",
      "Epoch 2/5\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.1124 - accuracy: 0.9652 - val_loss: 0.1069 - val_accuracy: 0.9697\n",
      "Epoch 3/5\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0798 - accuracy: 0.9745 - val_loss: 0.0957 - val_accuracy: 0.9730\n",
      "Epoch 4/5\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0599 - accuracy: 0.9812 - val_loss: 0.0867 - val_accuracy: 0.9735\n",
      "Epoch 5/5\n",
      "1313/1313 [==============================] - 2s 1ms/step - loss: 0.0466 - accuracy: 0.9851 - val_loss: 0.0863 - val_accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 46058), started 0:47:29 ago. (Use '!kill 46058' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bb51203eea748316\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bb51203eea748316\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and compile the model\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam', # Use adaptive momentum estimation for adaptive gradient algorithm\n",
    "              loss='sparse_categorical_crossentropy', # Use cross-entropy loss function for classification\n",
    "              metrics=['accuracy']) # Use accuracy as the metric\n",
    "\n",
    "# Setup TensorBoard logging\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model with the training set and validate with the validation set\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])\n",
    "\n",
    "# Start TensorBoard within the notebook\n",
    "\n",
    "!rm -rf ./logs/\n",
    "%tensorboard --logdir logs/fit\n",
    "!rm -rf ./logs/\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "# Log the test metrics to TensorBoard\n",
    "with tf.summary.create_file_writer(log_dir).as_default():\n",
    "  tf.summary.scalar('test_loss', test_loss, step=1)\n",
    "  tf.summary.scalar('test_accuracy', test_acc, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/5\n",
    "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2420 - accuracy: 0.9295 - val_loss: 0.1149 - val_accuracy: 0.9664\n",
    "\n",
    "Epoch 2/5\n",
    "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1056 - accuracy: 0.9682 - val_loss: 0.0855 - val_accuracy: 0.9736\n",
    "\n",
    "Epoch 3/5\n",
    "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0730 - accuracy: 0.9774 - val_loss: 0.0879 - val_accuracy: 0.9704\n",
    "\n",
    "Epoch 4/5\n",
    "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0557 - accuracy: 0.9824 - val_loss: 0.0717 - val_accuracy: 0.9773\n",
    "\n",
    "Epoch 5/5\n",
    "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0452 - accuracy: 0.9855 - val_loss: 0.0656 - val_accuracy: 0.9786\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1 ...\n",
      "Epoch 1/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.2238 - accuracy: 0.9344\n",
      "Epoch 2/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0982 - accuracy: 0.9696\n",
      "Epoch 3/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0708 - accuracy: 0.9780\n",
      "Epoch 4/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0550 - accuracy: 0.9819\n",
      "Epoch 5/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0444 - accuracy: 0.9856\n",
      "Training for fold 2 ...\n",
      "Epoch 1/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.2234 - accuracy: 0.9334\n",
      "Epoch 2/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0977 - accuracy: 0.9695\n",
      "Epoch 3/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0696 - accuracy: 0.9781\n",
      "Epoch 4/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0532 - accuracy: 0.9834\n",
      "Epoch 5/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0439 - accuracy: 0.9858\n",
      "Training for fold 3 ...\n",
      "Epoch 1/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.2222 - accuracy: 0.9335\n",
      "Epoch 2/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0974 - accuracy: 0.9702\n",
      "Epoch 3/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0680 - accuracy: 0.9786\n",
      "Epoch 4/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0515 - accuracy: 0.9833\n",
      "Epoch 5/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0429 - accuracy: 0.9863\n",
      "Training for fold 4 ...\n",
      "Epoch 1/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.2218 - accuracy: 0.9336\n",
      "Epoch 2/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0979 - accuracy: 0.9695\n",
      "Epoch 3/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0692 - accuracy: 0.9786\n",
      "Epoch 4/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0548 - accuracy: 0.9826\n",
      "Epoch 5/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0442 - accuracy: 0.9857\n",
      "Training for fold 5 ...\n",
      "Epoch 1/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.2240 - accuracy: 0.9335\n",
      "Epoch 2/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0969 - accuracy: 0.9696\n",
      "Epoch 3/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0682 - accuracy: 0.9782\n",
      "Epoch 4/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0539 - accuracy: 0.9826\n",
      "Epoch 5/5\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 0.0420 - accuracy: 0.9863\n",
      "Score per fold: [[0.06947366893291473, 0.980571448802948], [0.07631673663854599, 0.9780714511871338], [0.07134383916854858, 0.9782857298851013], [0.06899403780698776, 0.9802142977714539], [0.07375606149435043, 0.9796428680419922]]\n",
      "------------------------------------------------------------------------\n",
      "> Accuracy: 0.5256670139729976 (+- 0.4536948461260527)\n",
      "------------------------------------------------------------------------\n",
      "model_1.h5: [0.029858538880944252, 0.9898333549499512]\n",
      "model_2.h5: [0.03471221774816513, 0.9890000224113464]\n",
      "model_3.h5: [0.030117541551589966, 0.9904999732971191]\n",
      "model_4.h5: [0.034781813621520996, 0.9903333187103271]\n",
      "model_5.h5: [0.033604055643081665, 0.9903333187103271]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Initialize results and models list\n",
    "scores = []\n",
    "models = []\n",
    "fold_no = 0\n",
    "\n",
    "# Loop through the indices the split() method returns\n",
    "for train, test in kfold.split(x, y):\n",
    "    fold_no += 1\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # Create and compile the model\n",
    "    model = create_model()\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Fit data to model\n",
    "    model.fit(x[train], y[train], epochs=5)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(f'model_{fold_no}.h5')\n",
    "    models.append(f'model_{fold_no}.h5')\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores.append(model.evaluate(x[test], y[test], verbose=0))\n",
    "\n",
    "# == Provide average scores ==\n",
    "print(f'Score per fold: {scores}')\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'> Accuracy: {np.mean(scores)} (+- {np.std(scores)})')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# Load and evaluate each saved model\n",
    "for model_file in models:\n",
    "    model = load_model(model_file)\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f'{model_file}: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
